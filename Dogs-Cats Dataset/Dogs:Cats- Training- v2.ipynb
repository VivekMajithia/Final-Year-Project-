{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Re_aDPdubnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import tensorflow_datasets as tfds\n",
        "(dataset, dataset_info) = tfds.load('cats_vs_dogs', split='train[:90%]', with_info=True, as_supervised=True)\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
        "    image = tf.image.random_hue(image, max_delta=0.1)\n",
        "    image = tf.image.random_saturation(image, lower=0.2, upper=1.8)\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    label = tf.one_hot(label, num_classes)\n",
        "    return image, label\n",
        "dataset = dataset.map(preprocess_image)\n",
        "num_samples = dataset_info.splits['train[:90%]'].num_examples\n",
        "num_train_samples = int(0.8 * num_samples)\n",
        "train_dataset = dataset.take(num_train_samples)\n",
        "val_dataset = dataset.skip(num_train_samples)\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "class TrainingAccuracyCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch + 1}/{self.params['epochs']} - Training Accuracy: {logs['accuracy']:.4f}\")\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    #Dropout(0.5),- Increased accuracy after commenting this\n",
        "    Dense(num_classes, activation='softmax')\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "accuracy_callback = TrainingAccuracyCallback()\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=[accuracy_callback])\n",
        "final_training_accuracy = history.history['accuracy'][-1]\n",
        "print(\"Training accuracy:\", final_training_accuracy)\n",
        "#Here is my attempt to see how much training accuracy we are getting after training the model to ensure that it is ready for training prior to unseen data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq5IRpj6ieBS",
        "outputId": "11810a4c-a19f-47c9-cf93-c651a93b9adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "524/524 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.5911Epoch 1/10 - Training Accuracy: 0.5911\n",
            "524/524 [==============================] - 132s 247ms/step - loss: 0.7032 - accuracy: 0.5911 - val_loss: 0.5684 - val_accuracy: 0.6920\n",
            "Epoch 2/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.7413Epoch 2/10 - Training Accuracy: 0.7415\n",
            "524/524 [==============================] - 126s 241ms/step - loss: 0.5162 - accuracy: 0.7415 - val_loss: 0.4831 - val_accuracy: 0.7603\n",
            "Epoch 3/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8022Epoch 3/10 - Training Accuracy: 0.8022\n",
            "524/524 [==============================] - 147s 280ms/step - loss: 0.4276 - accuracy: 0.8022 - val_loss: 0.4371 - val_accuracy: 0.7904\n",
            "Epoch 4/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8484Epoch 4/10 - Training Accuracy: 0.8485\n",
            "524/524 [==============================] - 125s 239ms/step - loss: 0.3508 - accuracy: 0.8485 - val_loss: 0.4563 - val_accuracy: 0.7887\n",
            "Epoch 5/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.8874Epoch 5/10 - Training Accuracy: 0.8873\n",
            "524/524 [==============================] - 127s 242ms/step - loss: 0.2805 - accuracy: 0.8873 - val_loss: 0.4830 - val_accuracy: 0.7985\n",
            "Epoch 6/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9178Epoch 6/10 - Training Accuracy: 0.9178\n",
            "524/524 [==============================] - 125s 238ms/step - loss: 0.2146 - accuracy: 0.9178 - val_loss: 0.5723 - val_accuracy: 0.8023\n",
            "Epoch 7/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9418Epoch 7/10 - Training Accuracy: 0.9418\n",
            "524/524 [==============================] - 127s 242ms/step - loss: 0.1604 - accuracy: 0.9418 - val_loss: 0.6213 - val_accuracy: 0.8092\n",
            "Epoch 8/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9581Epoch 8/10 - Training Accuracy: 0.9581\n",
            "524/524 [==============================] - 126s 241ms/step - loss: 0.1207 - accuracy: 0.9581 - val_loss: 0.7384 - val_accuracy: 0.7935\n",
            "Epoch 9/10\n",
            "523/524 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9695Epoch 9/10 - Training Accuracy: 0.9695\n",
            "524/524 [==============================] - 124s 237ms/step - loss: 0.0917 - accuracy: 0.9695 - val_loss: 0.8013 - val_accuracy: 0.7958\n",
            "Epoch 10/10\n",
            "524/524 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9775Epoch 10/10 - Training Accuracy: 0.9775\n",
            "524/524 [==============================] - 124s 237ms/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 0.8751 - val_accuracy: 0.8042\n",
            "Training accuracy: 0.9775495529174805\n"
          ]
        }
      ]
    }
  ]
}