# Final-Year-Project


Artificial intelligence has become an integral part of the modern society’s day-to-day lives, where applications of it from image classification to autonomous driving. However, the reliability of AI systems against manipulations remains a critical concern. This research investigates the vulnerabilities of AI image classifiers against adversarial manipulations and proposes why robustness of AI has to be considered in order to adopt it more confidently in critical domains.

The project emphasises the importance of understanding these limitations, particularly in domains where AI systems are tasked to classify diverse objects, healthcare would be one of the most critical examples. Adversarial attacks are highly advanced where it involves subtle manipulations which manipulate the input data to deceive AI classifiers which poses a significant threat to the integrity of these systems.

This research seeks to answer crucial questions regarding the extent of training required for AI systems in order to reliably detect adversarial manipulations and to develop solutions to address this vulnerability. By conducting thorough evaluations of the model’s response to adversarial attacks, the project aims to contribute to the development of more robust and secure AI systems which leads to higher confidence of its adoption in highly critical domains such as healthcare.

To conclude, this research explores the vulnerabilities of AI image classifiers and proposes strategies to mitigate the risks posed by adversarial attacks.
 
